{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expresiones Regulares y Autómatas Finitos\n",
    "Notas de clase sobre Teoría de la Compilación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juan David Velásquez Henao**   \n",
    "jdvelasq@unal.edu.co  \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia  \n",
    "\n",
    "[Licencia](https://github.com/jdvelasq/teoria-de-la-compilacion/blob/master/LICENCIA.txt)  \n",
    "[Readme](https://github.com/jdvelasq/teoria-de-la-compilacion/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software utilizado**.\n",
    "\n",
    "> Este es un documento interactivo escrito como un notebook de [Jupyter](http://jupyter.org), en el cual se presenta una introducción al diseño de lectores, generadores, traductores, interpretes y compiladores. Los notebooks de Jupyter permiten incoporar simultáneamente código, texto, gráficos y ecuaciones. El código presentado en este notebook puede ejecutarse en los sistemas operativos Windows, Linux y OS X.\n",
    "\n",
    "> Haga click [aquí](https://github.com/jdvelasq/guias-de-instalacion) para obtener instrucciones detalladas sobre como instalar Jupyter en Windows y Mac OS X.\n",
    "\n",
    "> Haga clic [aquí](http://nbviewer.jupyter.org/github/jdvelasq/teoria-de-la-compilacion/blob/master/tcc-03-expreg-y-automatas.ipynb) para ver la última versión de este documento en nbviewer.\n",
    "\n",
    "> Descargue la última versión de este documento, los archivos de datos y los programas en Python a su disco duro; luego, carguelos y ejecutelos en línea en [Try Jupyter!](https://try.jupyter.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * [Introducción](#Introducción)\n",
    "    * [Definiciones](#Definiciones)\n",
    "    * [Proceso de reconocimiento](#Proceso-de-reconocimiento)\n",
    "* [Expresiones Regulares](#Expresiones-Regulares)\n",
    "    * [Expresión regular](#Expresión-regular)\n",
    "    * [Operaciones](#Operaciones)\n",
    "    * [Ejemplo](#Ejemplo)\n",
    "* [`grep.py` - Búsqueda usando expresiones regulares](#grep.py---Búsqueda-usando-expresiones-regulares)\n",
    "    * [Operadores](#Operadores)\n",
    "    * [Ejemplos](#Ejemplos)\n",
    "* [Autómatas Finitos](#Autómatas-Finitos)\n",
    "    * [Autómata Finito Determinista (AFD)](#Autómata-Finito-Determinista)\n",
    "    * [Autómata Finito no Determinista (AFN)  ](#Autómata-Finito-no-Determinista)\n",
    "    * [Construcción de un AFD a partir de un AFN](#Construcción-de-un-AFD-a-partir-de-un-AFN)\n",
    "* [`resplit.py` - Reconocimiento usando autómatas finitos](#resplit.py---Reconocimiento-usando-autómatas-finitos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definiciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>**Análisis Léxico**</big>  \n",
    "Proceso que clasifica el código fuente en sus distintas partes constitutivas.\n",
    "\n",
    "<big>**Token**</big>  \n",
    "Tipo (clase) a la que pertenece una cadena de caracteres.\n",
    "\n",
    "<big>**Lexema**</big>   \n",
    "Cadena de texto (instancia del token).\n",
    "\n",
    "<big>**Tipos comunes de tokens**</big>  \n",
    "*\tPalabras reservadas: `if`, `while`, `for`, `repeat`, ...\n",
    "*\tNúmeros: enteros, flotantes, binarios, ...\n",
    "*\tIdentificadores.\n",
    "*\tOperadores: `+`, `-`, `*`, `/`, `<`, `>=`, ...\n",
    "*\tComentarios: `#`, `/* ... */`, `//`, ...\n",
    "*\tOtros: `;` `,` `:` ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proceso de reconocimiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lectura del código fuente de izquierda a derecha y de arriba hacia abajo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Identificación del lexema.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Clasificación del lexema en una de las clases de tokens.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Almacenamiento de propiedades de cada lexema.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "```\n",
    "#\n",
    "# 004 var n:num, i:num, j:num;\n",
    "#\n",
    "VAR\n",
    "ID, name = n\n",
    ":\n",
    "DATATYPE: num\n",
    ",\n",
    "ID, name = i\n",
    ":\n",
    "DATATYPE: num\n",
    ",\n",
    "ID, name = j\n",
    ":\n",
    "DATATYPE: num\n",
    ";\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expresiones Regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expresión regular"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Patrón que representa un conjunto de cadenas de caracteres (representa tokens)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El carácter $a \\in \\sum$ es una expresión regular simple.  $\\sum$ es el alfabeto. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El carácter $\\epsilon$ representa la cadena vacia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El símbolo $\\phi$ representa el conjunto vacio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El operador $L(\\dot)$ representa las cadenas de caracteres que se obtienen a partir de una expresión regular. Ejemplo: $L(a) = \\{a\\},  L(\\epsilon) = \\{\\epsilon\\},  L(\\phi) = \\{ \\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sea el alfabeto $\\sum = \\{a, b\\}$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Concatenación: $L(ab) = \\{ ab \\}$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Unión: $L(a|b) = \\{a, b\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Repetición:  \n",
    "    + $L(a^*) = \\{\\epsilon, a, aa, aaa, \\dots\\}$\n",
    "    + $L(a^+) = \\{a, aa, aaa, \\dots\\}$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sea el alfabeto $\\Sigma = \\{a, b, c\\}$. Describa verbalmente el conjunto de cadenas generadas por las siguientes expresiones regulares:\n",
    "\n",
    "  <br>\n",
    "\n",
    "  * `(a|c)*b(a|c)*`\n",
    "\n",
    "  <br>\n",
    "\n",
    "  * `(a|c)* | (a|c)*b(a|c)*`\n",
    "\n",
    "  <br>\n",
    "\n",
    "  * `(a|c)* | (b(a|c)*)*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sea el alfabeto $\\Sigma = \\{0, 1\\}$. Liste las cadenas generadas por la expresión regular \n",
    " `(0|1) 1 (0|1)` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# `grep.py` - Búsqueda usando expresiones regulares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`.`** -- Indica cualquier carácter.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`^a`** -- ‘a’ cuando está al principio de la línea.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`a$`** -- ‘a’ cuando está al final de la línea.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`a*`** --\tcero o más ocurrencias del carácter ‘a’.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`^$`** -- la línea vacía.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001: \u001b[37m###< 2016-08-28 17:04:40.187160 >###\u001b[39;49;00m\n",
      "0002: \n",
      "0003: \u001b[37m##\u001b[39;49;00m\n",
      "0004: \u001b[37m##  grep.py (grep en python)\u001b[39;49;00m\n",
      "0005: \u001b[37m##\u001b[39;49;00m\n",
      "0006: \u001b[37m##    implementacion de grep (basico) en python\u001b[39;49;00m\n",
      "0007: \u001b[37m##    (Adaptacion del codigo de Kernighan y Pike\u001b[39;49;00m\n",
      "0008: \u001b[37m##    publicado en Dr Dobbs).\u001b[39;49;00m\n",
      "0009: \u001b[37m##\u001b[39;49;00m\n",
      "0010: \n",
      "0011: \n",
      "0012: \u001b[37m## librería para leer los argumentos de la línea de comandos\u001b[39;49;00m\n",
      "0013: \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "0014: \n",
      "0015: \n",
      "0016: \u001b[37m## la búsqueda se realiza sobre la línea actual de texto\u001b[39;49;00m\n",
      "0017: \u001b[34mdef\u001b[39;49;00m \u001b[32mmatch_here\u001b[39;49;00m(re, text):\n",
      "0018:     \u001b[33m'''\u001b[39;49;00m\n",
      "0019: \u001b[33m    Busca la cadena re al principio de la cadena text\u001b[39;49;00m\n",
      "0020: \u001b[33m    por eliminación de los caracteres iguales en re y text\u001b[39;49;00m\n",
      "0021: \u001b[33m\u001b[39;49;00m\n",
      "0022: \u001b[33m    Ejemplo 1:\u001b[39;49;00m\n",
      "0023: \u001b[33m       matchhere( ‘mundo’, ‘mundo feliz’)  # llamada recursiva en el último if\u001b[39;49;00m\n",
      "0024: \u001b[33m       matchhere( ‘undo’, ‘undo feliz’)\u001b[39;49;00m\n",
      "0025: \u001b[33m       matchhere( ‘ndo’, ‘ndo feliz’)\u001b[39;49;00m\n",
      "0026: \u001b[33m       matchhere( ‘do’, ‘do feliz’)\u001b[39;49;00m\n",
      "0027: \u001b[33m       matchhere( ‘o’, ‘o feliz’)\u001b[39;49;00m\n",
      "0028: \u001b[33m       matchhere( ‘’, ‘ feliz’)  ← True  por el primer if\u001b[39;49;00m\n",
      "0029: \u001b[33m\u001b[39;49;00m\n",
      "0030: \u001b[33m    Ejemplo 2:\u001b[39;49;00m\n",
      "0031: \u001b[33m       matchhere( ‘mundo$’, ‘mundo’)  # llamada recursiva en el último if\u001b[39;49;00m\n",
      "0032: \u001b[33m       matchhere( ‘undo$’, ‘undo’)\u001b[39;49;00m\n",
      "0033: \u001b[33m       matchhere( ‘ndo$’, ‘ndo’)\u001b[39;49;00m\n",
      "0034: \u001b[33m       matchhere( ‘do$’, ‘do’)\u001b[39;49;00m\n",
      "0035: \u001b[33m       matchhere( ‘o$’, ‘o’)\u001b[39;49;00m\n",
      "0036: \u001b[33m       matchhere( ‘$’, ‘’)  ← True  por el tercer if\u001b[39;49;00m\n",
      "0037: \u001b[33m    '''\u001b[39;49;00m\n",
      "0038: \n",
      "0039:     \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(re) == \u001b[34m0\u001b[39;49;00m:\n",
      "0040:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mTrue\u001b[39;49;00m\n",
      "0041: \n",
      "0042:     \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(re) > \u001b[34m1\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m re[\u001b[34m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0043:         \u001b[34mreturn\u001b[39;49;00m match_star(re[\u001b[34m0\u001b[39;49;00m], re[\u001b[34m2\u001b[39;49;00m:], text)\n",
      "0044: \n",
      "0045: \n",
      "0046:     \u001b[34mif\u001b[39;49;00m re[\u001b[34m0\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(re)==\u001b[34m1\u001b[39;49;00m:\n",
      "0047:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(text) == \u001b[34m0\u001b[39;49;00m\n",
      "0048: \n",
      "0049:     \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(text)>\u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m (re[\u001b[34m0\u001b[39;49;00m]==\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m re[\u001b[34m0\u001b[39;49;00m] == text[\u001b[34m0\u001b[39;49;00m]):\n",
      "0050:         \u001b[34mreturn\u001b[39;49;00m match_here(re[\u001b[34m1\u001b[39;49;00m:], text[\u001b[34m1\u001b[39;49;00m:])\n",
      "0051: \n",
      "0052:     \u001b[34mreturn\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\n",
      "0053: \n",
      "0054: \n",
      "0055: \u001b[37m#\u001b[39;49;00m\n",
      "0056: \u001b[37m#    busca c*re al principio del texto\u001b[39;49;00m\n",
      "0057: \u001b[37m#\u001b[39;49;00m\n",
      "0058: \u001b[34mdef\u001b[39;49;00m \u001b[32mmatch_star\u001b[39;49;00m(c, re, text):\n",
      "0059:     \u001b[33m'''\u001b[39;49;00m\n",
      "0060: \u001b[33m    busca c*re al principio del texto\u001b[39;49;00m\n",
      "0061: \u001b[33m\u001b[39;49;00m\n",
      "0062: \u001b[33m    Ejemplo:\u001b[39;49;00m\n",
      "0063: \u001b[33m       grep(‘a*bb’, ‘aabbb’)\u001b[39;49;00m\n",
      "0064: \u001b[33m       matchstar( ‘a’, ‘bb’, ‘aabbb’)\u001b[39;49;00m\n",
      "0065: \u001b[33m       matchhere( ‘bb’, ‘aabbb’) ← False\u001b[39;49;00m\n",
      "0066: \u001b[33m       matchhere( ‘bb’, ‘abbb’)  ← False\u001b[39;49;00m\n",
      "0067: \u001b[33m       matchhere( ‘bb’, ‘bbb’)   ← True\u001b[39;49;00m\n",
      "0068: \u001b[33m    '''\u001b[39;49;00m\n",
      "0069: \n",
      "0070:     \u001b[34mwhile\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(text) > \u001b[34m0\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m (text[\u001b[34m0\u001b[39;49;00m] == c \u001b[35mor\u001b[39;49;00m c == \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "0071:         \u001b[34mif\u001b[39;49;00m match_here(re, text):\n",
      "0072:             \u001b[34mreturn\u001b[39;49;00m \u001b[36mTrue\u001b[39;49;00m\n",
      "0073:         text = text[\u001b[34m1\u001b[39;49;00m:]\n",
      "0074:     \u001b[34mreturn\u001b[39;49;00m match(re, text)\n",
      "0075: \n",
      "0076: \n",
      "0077: \n",
      "0078: \n",
      "0079: \n",
      "0080: \n",
      "0081: \u001b[37m#\u001b[39;49;00m\n",
      "0082: \u001b[37m#    esta es la funcion de busqueda.\u001b[39;49;00m\n",
      "0083: \u001b[37m#    busca la ocurrencia de la expresion regular en 'text'\u001b[39;49;00m\n",
      "0084: \u001b[37m#\u001b[39;49;00m\n",
      "0085: \u001b[34mdef\u001b[39;49;00m \u001b[32mmatch\u001b[39;49;00m(re, text):\n",
      "0086:     \u001b[33m'''\u001b[39;49;00m\n",
      "0087: \u001b[33m    Esta es la funcion de busqueda.\u001b[39;49;00m\n",
      "0088: \u001b[33m    Busca la ocurrencia de la expresion regular re en text\u001b[39;49;00m\n",
      "0089: \u001b[33m\u001b[39;49;00m\n",
      "0090: \u001b[33m    Ejemplo:\u001b[39;49;00m\n",
      "0091: \u001b[33m       match( ‘mundo’, ‘hola mundo feliz’)\u001b[39;49;00m\n",
      "0092: \u001b[33m       match( ‘mundo’, ‘ola mundo feliz’)\u001b[39;49;00m\n",
      "0093: \u001b[33m       match( ‘mundo’, ‘la mundo feliz’)\u001b[39;49;00m\n",
      "0094: \u001b[33m       match( ‘mundo’, ‘a mundo feliz’)\u001b[39;49;00m\n",
      "0095: \u001b[33m       match( ‘mundo’, ‘ mundo feliz’)\u001b[39;49;00m\n",
      "0096: \u001b[33m       match( ‘mundo’, ‘mundo feliz’)  ← True\u001b[39;49;00m\n",
      "0097: \u001b[33m\u001b[39;49;00m\n",
      "0098: \u001b[33m    '''\u001b[39;49;00m\n",
      "0099:     \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(re) == \u001b[34m0\u001b[39;49;00m:\n",
      "0100:         \u001b[37m#\u001b[39;49;00m\n",
      "0101:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mTrue\u001b[39;49;00m\n",
      "0102:         \u001b[37m#\u001b[39;49;00m\n",
      "0103: \n",
      "0104:     \u001b[34mif\u001b[39;49;00m re[\u001b[34m0\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m^\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0105:         \u001b[37m#\u001b[39;49;00m\n",
      "0106:         \u001b[34mreturn\u001b[39;49;00m match_here(re[\u001b[34m1\u001b[39;49;00m:], text)\n",
      "0107:         \u001b[37m#\u001b[39;49;00m\n",
      "0108: \n",
      "0109:     \u001b[34mwhile\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(text) > \u001b[34m0\u001b[39;49;00m:\n",
      "0110: \n",
      "0111:         \u001b[34mif\u001b[39;49;00m match_here(re, text):\n",
      "0112:             \u001b[34mreturn\u001b[39;49;00m \u001b[36mTrue\u001b[39;49;00m\n",
      "0113:         text = text[\u001b[34m1\u001b[39;49;00m:]\n",
      "0114: \n",
      "0115:     \u001b[34mreturn\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\n",
      "0116: \n",
      "0117: \u001b[34mdef\u001b[39;49;00m \u001b[32mdo_search\u001b[39;49;00m(re, filename, print_header):\n",
      "0118:     \u001b[33m'''\u001b[39;49;00m\n",
      "0119: \u001b[33m    llama la funcion de busqueda (match) para\u001b[39;49;00m\n",
      "0120: \u001b[33m    cada una de las lineas del archivo analizado\u001b[39;49;00m\n",
      "0121: \u001b[33m    '''\u001b[39;49;00m\n",
      "0122:     \u001b[37m## abre el archivo y lo lee completamente\u001b[39;49;00m\n",
      "0123:     lines = \u001b[36mopen\u001b[39;49;00m(filename, \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).readlines()\n",
      "0124: \n",
      "0125:     \u001b[37m## lines es una lista de strings donde el último\u001b[39;49;00m\n",
      "0126:     \u001b[37m## caracter es un retorno de carro\u001b[39;49;00m\n",
      "0127:     \u001b[34mfor\u001b[39;49;00m text \u001b[35min\u001b[39;49;00m lines:\n",
      "0128: \n",
      "0129:         \u001b[37m## elimina el retorno de carro al final de string\u001b[39;49;00m\n",
      "0130:         \u001b[34mif\u001b[39;49;00m text[-\u001b[34m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0131:             text = text[:-\u001b[34m1\u001b[39;49;00m]\n",
      "0132: \n",
      "0133:         \u001b[37m## llama a match para buscar re en text\u001b[39;49;00m\n",
      "0134:         \u001b[34mif\u001b[39;49;00m match(re, text):\n",
      "0135:             \u001b[34mif\u001b[39;49;00m print_header:\n",
      "0136:                 \u001b[37m#\u001b[39;49;00m\n",
      "0137:                 \u001b[34mprint\u001b[39;49;00m(filename+\u001b[33m\"\u001b[39;49;00m\u001b[33m:\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, end=\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0138:                 \u001b[37m#\u001b[39;49;00m\n",
      "0139:             \u001b[34mprint\u001b[39;49;00m(text)\n",
      "0140: \n",
      "0141: \n",
      "0142: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m011\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mFalse\u001b[39;49;00m\n",
      "0143: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0144: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m00$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mFalse\u001b[39;49;00m\n",
      "0145: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m01$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0146: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m^10\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mFalse\u001b[39;49;00m\n",
      "0147: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m^00\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001 1001 001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0148: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33ma01*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m00a 100a 00a\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mFalse\u001b[39;49;00m\n",
      "0149: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m000*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m111 00a1 0a1\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0150: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33mab*c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mac\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0151: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33mab*c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mabc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0152: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33mab*c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mabbc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0153: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33ma.c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ma0c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0154: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m^0.1$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m000\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mFalse\u001b[39;49;00m\n",
      "0155: \u001b[34massert\u001b[39;49;00m match(\u001b[33m'\u001b[39;49;00m\u001b[33m^0.1$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33m001\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[36mTrue\u001b[39;49;00m\n",
      "0156: \n",
      "0157: \n",
      "0158: \n",
      "0159: \u001b[37m##\u001b[39;49;00m\n",
      "0160: \u001b[37m##  programa principal\u001b[39;49;00m\n",
      "0161: \u001b[37m##\u001b[39;49;00m\n",
      "0162: \u001b[37m##    realiza la busqueda para cada uno de los archivos\u001b[39;49;00m\n",
      "0163: \u001b[37m##    pasados en la CML\u001b[39;49;00m\n",
      "0164: \u001b[37m##\u001b[39;49;00m\n",
      "0165: \u001b[34mif\u001b[39;49;00m __name__ == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) >= \u001b[34m3\u001b[39;49;00m:\n",
      "0166: \n",
      "0167:     print_header = \u001b[36mTrue\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) > \u001b[34m3\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\n",
      "0168:     \n",
      "0169:     re = sys.argv[\u001b[34m1\u001b[39;49;00m]\n",
      "0170: \n",
      "0171:     \u001b[34mfor\u001b[39;49;00m filename \u001b[35min\u001b[39;49;00m sys.argv[\u001b[34m2\u001b[39;49;00m:]:\n",
      "0172:         \u001b[37m#\u001b[39;49;00m\n",
      "0173:         do_search(re, filename, print_header)\n",
      "0174:         \u001b[37m#\u001b[39;49;00m\n",
      "0175: \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize -O linenos=1 -g grep.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca la cadena de texto `def` en los archivos `yylex.py` y `yyparse.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yylex.py:def yylex(filename, quiet=False):\n",
      "yylex.py:    def yyputtoken(token, lexeme, lineno):\n",
      "yyparse.py:def yyparse(filename, quiet = False):\n",
      "yyparse.py:    def yytext(offset=0):\n",
      "yyparse.py:    def yytoken(offset=0):\n",
      "yyparse.py:    def yymatch(token, offset=0):\n",
      "yyparse.py:    def yyadvance(offset=1):\n",
      "yyparse.py:    def yylineno():\n",
      "yyparse.py:    def yyaccept(token, advance=True):\n",
      "yyparse.py:    def yynewnode(kind, datatype=None, value=None, scope=None):\n",
      "yyparse.py:    def program():\n",
      "yyparse.py:    def var_decl():\n",
      "yyparse.py:    def function_decl():\n",
      "yyparse.py:    def main_prog():\n",
      "yyparse.py:    def stmt_block():\n",
      "yyparse.py:    def stmt():\n",
      "yyparse.py:    def lexpr():\n",
      "yyparse.py:    def nexpr():\n",
      "yyparse.py:    def rexpr():\n",
      "yyparse.py:    def simple_expr():\n",
      "yyparse.py:    def term():\n",
      "yyparse.py:    def factor():\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py def yylex.py  yyparse.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busca la cadena de texto `def` al principio de la línea en el archivo `yylex.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def yylex(filename, quiet=False):\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py ^def yylex.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                msg += 'Unexpected symbol <{}>'.format(lex1)\n",
      "                # msg += '--> ' + sourceCode[lineno]\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py 'msg +=' yylex.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genera un archivo de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat > out.txt <<EOF\n",
    "00010 09001 40010 0011A\n",
    "01000 010B1 011A0 0111A\n",
    "19010 10A01 16010 10110\n",
    "A1B80 11819 17110 1111B\n",
    "00031 11015 11910 11114\n",
    "11090 11041 11130 00003\n",
    "EOF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las líneas que contengan `000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00010 09001 40010 0011A\n",
      "01000 010B1 011A0 0111A\n",
      "00031 11015 11910 11114\n",
      "11090 11041 11130 00003\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "python grep.py 000 out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las líneas que contengan un `11` al principio de la línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11090 11041 11130 00003\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py ^11 out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las líneas que terminen en `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00010 09001 40010 0011A\n",
      "01000 010B1 011A0 0111A\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py A$ out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todas las líneas que empiecen por `01` y terminen en `A`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01000 010B1 011A0 0111A\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "python grep.py ^01.*A$ out.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autómatas Finitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autómata Finito Determinista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un autómata finito determinista $M$ esta conformado por:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un alfabeto de símbolos $\\Sigma$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un conjunto de estados $S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Una función de transición $T:S \\times \\Sigma \\to S$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un estado inicial $S_0 \\in S$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Un conjunto de estados de aceptación $A \\subset S$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* El lenguaje aceptado por el autómata $M$ está definido por las cadenas de caracteres $c_1$, $c_2$, ..., $c_n$ que llevan el autómata $M$ desde el estado inicial hasta un estado de aceptación."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**  \n",
    "Indique las expresiones regulares que reconocen las mismas cadenas de texto que los siguientes autómatas finitos deterministas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/tcc-03-1-automatas.tiff)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**  \n",
    "Indique los lexemas en que los siguientes autómatas finitos deterministas dividen la cadena de texto presentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/tcc-03-2-automatas.tiff)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autómata Finito no Determinista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contiene transiciones $\\epsilon$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algoritmo para construir AFNs a partir de expresiones regulares**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/tcc-03-3-thompson.tiff)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**  \n",
    "Sea el alfabeto $\\sum = \\{a, b, c\\}$. Dibuje el autómata regular equivalente para cada una de las siguientes expresiones regulares:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`(a|c)*b(a|c)*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`(a|c)* | (a|c)*b(a|c)*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`(a|c)* | (b(a|c)*)*`  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construcción de un AFD a partir de un AFN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clausura-$\\epsilon$: estados alcanzables desde el estado actual mediante una transición $\\epsilon$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](images/tcc-03-4-thompson.tiff)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>1</u>** = {1,2,4}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>2</u>** = {2}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>3</u>** = {2, 3, 4}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<u>4</u>** = {4}  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio**  \n",
    "Encuentre el AFD equivalente a la expresión regular `abc | ab*d`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resplit.py - Reconocimiento usando autómatas finitos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dibuje un autómata finito determinista que reconozca las siguientes expresiones regulares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`b+ | ac+ | ab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`ab | cab+`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*\t`bbc* | bac*`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejercicio.--** Dibuje los autómatas regulares representados como (cada diccionario representa un estado):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `[ {'a':2, 'b':1},  {'b':1} , {'b':4, 'c': 3}, {'c':3}, {} ]`  \n",
    "   Estados de aceptación: [1, 3, 4]\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*  `[ {'a':1, 'c':3}, {'b':2}, {'b':2}, {'a':1}]`  \n",
    "   Estados de aceptación: [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `[ {'b':1}, {'a':3, 'b':2}, {'c':2}, {'c':3}]`  \n",
    "  Estados de aceptación: [2, 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso se escibirá un módulo en python llamado `resplit.py` que contiene las funciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001: \u001b[37m###< 2016-08-28 17:04:40.187647 >###\u001b[39;49;00m\n",
      "0002: \n",
      "0003: \u001b[37m#\u001b[39;49;00m\n",
      "0004: \u001b[37m#  resplit.py (split text using regular expresions)\u001b[39;49;00m\n",
      "0005: \u001b[37m#    esta funcion permite dividir una cadena de texto\u001b[39;49;00m\n",
      "0006: \u001b[37m#    en lexemas usando expresiones regulares (re)\u001b[39;49;00m\n",
      "0007: \u001b[37m#\u001b[39;49;00m\n",
      "0008: \u001b[37m#    ejemplo: resplit('abb*', 'ababbabbb') devuelve 'ab/abb/abbb'\u001b[39;49;00m\n",
      "0009: \u001b[37m# \u001b[39;49;00m\n",
      "0010: \n",
      "0011:  \n",
      "0012: \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "0013: \n",
      "0014: dfa = []\n",
      "0015: accept_states = []\n",
      "0016: \n",
      "0017: \u001b[37m# agrega c\u001b[39;49;00m\n",
      "0018: \u001b[34mdef\u001b[39;49;00m \u001b[32maddch\u001b[39;49;00m(state, c):\n",
      "0019:     next_state = \u001b[36mlen\u001b[39;49;00m(dfa)\n",
      "0020:     dfa.append(\u001b[36mdict\u001b[39;49;00m())\n",
      "0021:     dfa[state][c] = next_state\n",
      "0022:     \u001b[34mreturn\u001b[39;49;00m next_state\n",
      "0023: \n",
      "0024: \n",
      "0025: \u001b[37m# agrega c*\u001b[39;49;00m\n",
      "0026: \u001b[34mdef\u001b[39;49;00m \u001b[32maddch_star\u001b[39;49;00m(state, c):\n",
      "0027:     dfa[state][c] = state\n",
      "0028:     \u001b[34mreturn\u001b[39;49;00m state\n",
      "0029: \n",
      "0030: \n",
      "0031: \n",
      "0032: \n",
      "0033: \u001b[37m# construye la tabla de transiciones\u001b[39;49;00m\n",
      "0034: \u001b[37m# a partir de la expresion regular\u001b[39;49;00m\n",
      "0035: \u001b[34mdef\u001b[39;49;00m \u001b[32mdo_dfa\u001b[39;49;00m(re, text):\n",
      "0036:     pos = \u001b[34m0\u001b[39;49;00m\n",
      "0037:     state = \u001b[34m0\u001b[39;49;00m\n",
      "0038:     \u001b[34mwhile\u001b[39;49;00m pos < \u001b[36mlen\u001b[39;49;00m(re):\n",
      "0039:         \u001b[34mif\u001b[39;49;00m pos+\u001b[34m1\u001b[39;49;00m < \u001b[36mlen\u001b[39;49;00m(re) \u001b[35mand\u001b[39;49;00m re[pos+\u001b[34m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0040:             state = addch_star(state, re[pos])\n",
      "0041:             pos += \u001b[34m1\u001b[39;49;00m\n",
      "0042:         \u001b[34melse\u001b[39;49;00m:\n",
      "0043:             state = addch(state, re[pos])\n",
      "0044:         pos += \u001b[34m1\u001b[39;49;00m\n",
      "0045:     accept_states.append(state)\n",
      "0046:     \u001b[34mreturn\u001b[39;49;00m\n",
      "0047: \n",
      "0048: \n",
      "0049: \u001b[37m# recorre el dfa a partir de los caracteres\u001b[39;49;00m\n",
      "0050: \u001b[34mdef\u001b[39;49;00m \u001b[32msim_dfa\u001b[39;49;00m(text):\n",
      "0051:     state = \u001b[34m0\u001b[39;49;00m\n",
      "0052:     pos = \u001b[34m0\u001b[39;49;00m\n",
      "0053:     text_len = \u001b[34m0\u001b[39;49;00m\n",
      "0054:     \u001b[34mwhile\u001b[39;49;00m pos < \u001b[36mlen\u001b[39;49;00m(text) \u001b[35mand\u001b[39;49;00m state != -\u001b[34m1\u001b[39;49;00m:\n",
      "0055:         d = dfa[state]\n",
      "0056:         ch = text[pos]\n",
      "0057:         \u001b[34mif\u001b[39;49;00m ch \u001b[35min\u001b[39;49;00m d.keys():\n",
      "0058:             state = d[ch]\n",
      "0059:             \u001b[34mif\u001b[39;49;00m state \u001b[35min\u001b[39;49;00m accept_states:\n",
      "0060:                 text_len = pos+\u001b[34m1\u001b[39;49;00m\n",
      "0061:             pos += \u001b[34m1\u001b[39;49;00m\n",
      "0062:         \u001b[34melif\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35min\u001b[39;49;00m d.keys():\n",
      "0063:             state = d[\u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\n",
      "0064:             \u001b[34mif\u001b[39;49;00m state \u001b[35min\u001b[39;49;00m accept_states:\n",
      "0065:                 text_len = pos+\u001b[34m1\u001b[39;49;00m\n",
      "0066:             pos += \u001b[34m1\u001b[39;49;00m\n",
      "0067:         \u001b[34melse\u001b[39;49;00m:\n",
      "0068:             state = -\u001b[34m1\u001b[39;49;00m\n",
      "0069:     \u001b[34mreturn\u001b[39;49;00m text_len\n",
      "0070: \n",
      "0071: \n",
      "0072: \n",
      "0073: \u001b[34mdef\u001b[39;49;00m \u001b[32mresplit\u001b[39;49;00m(re, text, sep = \u001b[33m'\u001b[39;49;00m\u001b[33m/\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m):\n",
      "0074:     \u001b[34mdel\u001b[39;49;00m dfa[:]\n",
      "0075:     \u001b[34mdel\u001b[39;49;00m accept_states[:]\n",
      "0076:     dfa.append(\u001b[36mdict\u001b[39;49;00m())\n",
      "0077:     do_dfa(re, text)\n",
      "0078:     m = \u001b[34m0\u001b[39;49;00m\n",
      "0079:     n = \u001b[34m0\u001b[39;49;00m\n",
      "0080:     result = \u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0081:     \u001b[34mwhile\u001b[39;49;00m m < \u001b[36mlen\u001b[39;49;00m(text):\n",
      "0082:         n = sim_dfa(text[m:])\n",
      "0083:         \u001b[34mif\u001b[39;49;00m n == \u001b[34m0\u001b[39;49;00m:\n",
      "0084:             \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mFAIL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0085:         \u001b[34mif\u001b[39;49;00m m != \u001b[34m0\u001b[39;49;00m:\n",
      "0086:             result += sep\n",
      "0087:         result += text[m:m+n]\n",
      "0088:         m += n\n",
      "0089:     \u001b[34mreturn\u001b[39;49;00m result\n",
      "0090: \n",
      "0091: \n",
      "0092: \u001b[34massert\u001b[39;49;00m resplit(\u001b[33m'\u001b[39;49;00m\u001b[33mab0\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mabcabcabc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[33m'\u001b[39;49;00m\u001b[33mFAIL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0093: \u001b[34massert\u001b[39;49;00m resplit(\u001b[33m'\u001b[39;49;00m\u001b[33mabc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mabcabcabc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[33m'\u001b[39;49;00m\u001b[33mabc/abc/abc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0094: \u001b[34massert\u001b[39;49;00m resplit(\u001b[33m'\u001b[39;49;00m\u001b[33ma.c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ma0ca1ca2c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[33m'\u001b[39;49;00m\u001b[33ma0c/a1c/a2c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0095: \u001b[34massert\u001b[39;49;00m resplit(\u001b[33m'\u001b[39;49;00m\u001b[33mab*c\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33macabcabbcabbbc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) == \u001b[33m'\u001b[39;49;00m\u001b[33mac/abc/abbc/abbbc\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0096: \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize -O linenos=1 -g resplit.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import resplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'abc/abc/abc'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resplit.resplit('abc', 'abcabcabc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a0c/a1c/a2c'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resplit.resplit('a.c', 'a0ca1ca2c')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ac/abc/abbc/abbbc'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resplit.resplit('ab*c', 'acabcabbcabbbc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FAIL'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resplit.resplit('ab0', 'abcabcabc') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
