{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación manual de analizadores léxicos y manejo de estructuras de información\n",
    "Notas de clase sobre Teoría de la Compilación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Juan David Velásquez Henao**   \n",
    "jdvelasq@unal.edu.co  \n",
    "Universidad Nacional de Colombia, Sede Medellín  \n",
    "Facultad de Minas  \n",
    "Medellín, Colombia  \n",
    "\n",
    "[Licencia](https://github.com/jdvelasq/teoria-de-la-compilacion/blob/master/LICENCIA.txt)  \n",
    "[Readme](https://github.com/jdvelasq/teoria-de-la-compilacion/blob/master/readme.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Software utilizado**.\n",
    "\n",
    "> Este es un documento interactivo escrito como un notebook de [Jupyter](http://jupyter.org), en el cual se presenta una introducción al diseño de lectores, generadores, traductores, interpretes y compiladores. Los notebooks de Jupyter permiten incoporar simultáneamente código, texto, gráficos y ecuaciones. El código presentado en este notebook puede ejecutarse en los sistemas operativos Windows, Linux y OS X.\n",
    "\n",
    "> Haga click [aquí](https://github.com/jdvelasq/guias-de-instalacion) para obtener instrucciones detalladas sobre como instalar Jupyter en Windows y Mac OS X.\n",
    "\n",
    "> Haga clic [aquí](http://nbviewer.jupyter.org/github/jdvelasq/teoria-de-la-compilacion/blob/master/tcc-04-analisis-lexico.ipynb) para ver la última versión de este documento en nbviewer.\n",
    "\n",
    "> Descargue la última versión de este documento, los archivos de datos y los programas en Python a su disco duro; luego, carguelos y ejecutelos en línea en [Try Jupyter!](https://try.jupyter.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contenido"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">   * [dataTree.py](#dataTree.py)\n",
    "    * [Propiedades y funciones](#Propiedades-y-funciones)\n",
    "    * [Ejemplos](#Ejemplos)\n",
    "  * [shlex - Herramienta para construir analizadores léxicos sencillos](#shlex---Herramienta-para-construir-analizadores-léxicos-sencillos)\n",
    "  * [yylex.py - Analizador léxico para el lenguaje de prueba](#yylex.py---Analizador-léxico-para-el-lenguaje-de-prueba)\n",
    "    * [Gramática básica](#Gramática-básica.)\n",
    "  * [Ejemplos lenguaje bcc](#Ejemplos-lenguaje-bcc)\n",
    "  * [Gramática extendida (lenguaje final)](#Gramática-extendida-para-el-lenguaje-final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataTree.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es una estructura de datos, tipo arbol, que permite almacenar información en un formato similar al XML. La estructura base es el nodo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Propiedades y funciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`tag`** -- Es un string que representa el nombre clave del nodo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`attrib`** -- Es un diccionario que permite almacenar las propiedades de cada nodo.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`children`** -- Es una lista que contiene los nodos hijos del nodo actual.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`text`** -- Es un string que permite almacenar una cadena de texto adicional al tag.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001: \u001b[37m###< 2016-08-28 17:04:40.181913 >###\u001b[39;49;00m\n",
      "0002: \n",
      "0003: \u001b[33m\"\"\" DataTree for Python\u001b[39;49;00m\n",
      "0004: \u001b[33m\u001b[39;49;00m\n",
      "0005: \u001b[33mThis module implements a generic tree data structure for storing and\u001b[39;49;00m\n",
      "0006: \u001b[33mretrieving hierarchical information.\u001b[39;49;00m\n",
      "0007: \u001b[33m\u001b[39;49;00m\n",
      "0008: \u001b[33mThis data structure is used to store the information generated\u001b[39;49;00m\n",
      "0009: \u001b[33mduring the compilation process.\u001b[39;49;00m\n",
      "0010: \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "0011: \n",
      "0012: \u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mTreeNode\u001b[39;49;00m:\n",
      "0013:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, tag, attrib = {}):\n",
      "0014:         \u001b[36mself\u001b[39;49;00m.tag = tag\n",
      "0015:         \u001b[36mself\u001b[39;49;00m.attrib = attrib.copy()\n",
      "0016:         \u001b[36mself\u001b[39;49;00m._children = []\n",
      "0017:         \u001b[36mself\u001b[39;49;00m.text = \u001b[36mNone\u001b[39;49;00m\n",
      "0018: \n",
      "0019:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__repr__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0020:         \u001b[34mreturn\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m<Node {}>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[36mrepr\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.tag))\n",
      "0021: \n",
      "0022:     \u001b[37m# methods operating over subelements\u001b[39;49;00m\n",
      "0023:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__len__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0024:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m._children)\n",
      "0025: \n",
      "0026:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__iter__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0027:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children.__iter__()\n",
      "0028: \n",
      "0029:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__getitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index):\n",
      "0030:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children[index]\n",
      "0031: \n",
      "0032:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__setitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index, value):\n",
      "0033:         \u001b[36mself\u001b[39;49;00m._children[index] = value\n",
      "0034: \n",
      "0035:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__delitem__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index):\n",
      "0036:         \u001b[34mdel\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children[index]\n",
      "0037: \n",
      "0038:     \u001b[34mdef\u001b[39;49;00m \u001b[32m__str__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0039:         txt = \u001b[33m'\u001b[39;49;00m\u001b[33m{0}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(\u001b[36mself\u001b[39;49;00m.tag)\n",
      "0040:         \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.attrib):\n",
      "0041:             txt +=  \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0042:             keys = \u001b[36msorted\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.attrib.keys()))\n",
      "0043:             txt += \u001b[33m'\u001b[39;49;00m\u001b[33m{\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0044:             \u001b[34mfor\u001b[39;49;00m k \u001b[35min\u001b[39;49;00m keys:\n",
      "0045:                 txt += k + \u001b[33m'\u001b[39;49;00m\u001b[33m: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0046:                 txt += \u001b[36mstr\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.attrib[k])\n",
      "0047:                 \u001b[34mif\u001b[39;49;00m k != keys[-\u001b[34m1\u001b[39;49;00m]:\n",
      "0048:                     txt += \u001b[33m'\u001b[39;49;00m\u001b[33m, \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0049:             txt += \u001b[33m'\u001b[39;49;00m\u001b[33m}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0050:         \u001b[34mif\u001b[39;49;00m \u001b[35mnot\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.text \u001b[35mis\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m:\n",
      "0051:             txt += \u001b[33m'\u001b[39;49;00m\u001b[33m :\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mself\u001b[39;49;00m.text\n",
      "0052:         \u001b[34mreturn\u001b[39;49;00m txt\n",
      "0053: \n",
      "0054:     \u001b[34mdef\u001b[39;49;00m \u001b[32mappend\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, subnode):\n",
      "0055:         \u001b[36mself\u001b[39;49;00m._children.append(subnode)\n",
      "0056: \n",
      "0057:     \u001b[34mdef\u001b[39;49;00m \u001b[32mextend\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, subnodes):\n",
      "0058:         \u001b[36mself\u001b[39;49;00m._children.extend(subnodes)\n",
      "0059: \n",
      "0060:     \u001b[34mdef\u001b[39;49;00m \u001b[32minsert\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, index, subnode):\n",
      "0061:         \u001b[36mself\u001b[39;49;00m._children.insert(index, subnode)\n",
      "0062: \n",
      "0063:     \u001b[34mdef\u001b[39;49;00m \u001b[32mfind\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, match):\n",
      "0064:         \u001b[34mfor\u001b[39;49;00m node \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children:\n",
      "0065:             \u001b[34mif\u001b[39;49;00m node.tag == match:\n",
      "0066:                 \u001b[34mreturn\u001b[39;49;00m node\n",
      "0067:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m\n",
      "0068: \n",
      "0069:     \u001b[34mdef\u001b[39;49;00m \u001b[32mfindall\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, match):\n",
      "0070:         result = []\n",
      "0071:         \u001b[34mfor\u001b[39;49;00m node \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children:\n",
      "0072:             \u001b[34mif\u001b[39;49;00m node.tag == match:\n",
      "0073:                 result.append(node)\n",
      "0074:         \u001b[34mreturn\u001b[39;49;00m result\n",
      "0075: \n",
      "0076:     \u001b[34mdef\u001b[39;49;00m \u001b[32msearch\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, match, key, value):\n",
      "0077:         \u001b[34mfor\u001b[39;49;00m node \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children:\n",
      "0078:             \u001b[34mif\u001b[39;49;00m node.tag == match \u001b[35mand\u001b[39;49;00m node.attrib[key] == value:\n",
      "0079:                 \u001b[34mreturn\u001b[39;49;00m node\n",
      "0080:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m\n",
      "0081: \n",
      "0082:     \u001b[34mdef\u001b[39;49;00m \u001b[32msearchall\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, match, key, value):\n",
      "0083:         result = []\n",
      "0084:         \u001b[34mfor\u001b[39;49;00m node \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children:\n",
      "0085:             \u001b[34mif\u001b[39;49;00m node.tag == match \u001b[35mand\u001b[39;49;00m node.attrib[key] == value:\n",
      "0086:                 result.append(node)\n",
      "0087:         \u001b[34mreturn\u001b[39;49;00m result\n",
      "0088: \n",
      "0089: \n",
      "0090:     \u001b[34mdef\u001b[39;49;00m \u001b[32miter\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, tag=\u001b[36mNone\u001b[39;49;00m):\n",
      "0091:         \u001b[34mfor\u001b[39;49;00m e \u001b[35min\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m._children:\n",
      "0092:             \u001b[34myield from\u001b[39;49;00m e.iter(tag)\n",
      "0093: \n",
      "0094: \n",
      "0095:     \u001b[37m# metodos que operan sobre los atributos (dict)\u001b[39;49;00m\n",
      "0096:     \u001b[34mdef\u001b[39;49;00m \u001b[32mclear\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0097:         \u001b[36mself\u001b[39;49;00m.text = \u001b[36mNone\u001b[39;49;00m\n",
      "0098:         \u001b[36mself\u001b[39;49;00m.attrib.clear()\n",
      "0099:         \u001b[36mself\u001b[39;49;00m._children = []\n",
      "0100: \n",
      "0101:     \u001b[34mdef\u001b[39;49;00m \u001b[32mget\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, key, default=\u001b[36mNone\u001b[39;49;00m):\n",
      "0102:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.attrib.get(key, default)\n",
      "0103: \n",
      "0104:     \u001b[34mdef\u001b[39;49;00m \u001b[32mset\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, key, value):\n",
      "0105:         \u001b[36mself\u001b[39;49;00m.attrib[key] = value\n",
      "0106: \n",
      "0107:     \u001b[34mdef\u001b[39;49;00m \u001b[32mkeys\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0108:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.attrib.keys()\n",
      "0109: \n",
      "0110:     \u001b[34mdef\u001b[39;49;00m \u001b[32mvalues\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0111:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.attrib.values()\n",
      "0112: \n",
      "0113:     \u001b[34mdef\u001b[39;49;00m \u001b[32mitems\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m):\n",
      "0114:         \u001b[34mreturn\u001b[39;49;00m \u001b[36mself\u001b[39;49;00m.attrib.items()\n",
      "0115: \n",
      "0116: \u001b[37m# retorna el nodo creado\u001b[39;49;00m\n",
      "0117: \u001b[34mdef\u001b[39;49;00m \u001b[32mSubNode\u001b[39;49;00m(parent, tag, attrib = {}):\n",
      "0118:     parent.append(TreeNode(tag, attrib))\n",
      "0119:     \u001b[34mreturn\u001b[39;49;00m parent._children[-\u001b[34m1\u001b[39;49;00m]\n",
      "0120: \n",
      "0121: \u001b[34mdef\u001b[39;49;00m \u001b[32mprintTree\u001b[39;49;00m(node):\n",
      "0122:     \u001b[34mdef\u001b[39;49;00m \u001b[32mprintTreeNode\u001b[39;49;00m(prefix, node, lastNode):\n",
      "0123:         \u001b[34mprint\u001b[39;49;00m(prefix + \u001b[33m'\u001b[39;49;00m\u001b[33m+-- \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(node))\n",
      "0124:         \u001b[34mfor\u001b[39;49;00m i, n \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(node._children):\n",
      "0125:             isLastNode = \u001b[36mTrue\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m i == \u001b[36mlen\u001b[39;49;00m(node._children) - \u001b[34m1\u001b[39;49;00m \u001b[34melse\u001b[39;49;00m \u001b[36mFalse\u001b[39;49;00m\n",
      "0126:             \u001b[34mif\u001b[39;49;00m lastNode == \u001b[36mTrue\u001b[39;49;00m:\n",
      "0127:                 printTreeNode(prefix + \u001b[33m'\u001b[39;49;00m\u001b[33m    \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, n, isLastNode)\n",
      "0128:             \u001b[34melse\u001b[39;49;00m:\n",
      "0129:                 printTreeNode(prefix + \u001b[33m'\u001b[39;49;00m\u001b[33m|   \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, n, isLastNode)\n",
      "0130:     printTreeNode(\u001b[33m'\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, node, \u001b[36mTrue\u001b[39;49;00m)\n",
      "0131: \n",
      "0132: \u001b[34mdef\u001b[39;49;00m \u001b[32mcompTree\u001b[39;49;00m(tree1, tree2):\n",
      "0133:     \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\n",
      "0134: \n",
      "0135:     \u001b[34mdef\u001b[39;49;00m \u001b[32mprintError\u001b[39;49;00m(node1, node2, counter, text):\n",
      "0136:         \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mError: : \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + text)\n",
      "0137:         \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mExpected: [{:03d}] \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(counter) + \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(node1) + \\\n",
      "0138:               \u001b[33m'\u001b[39;49;00m\u001b[33m with \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(node1._children)) + \u001b[33m'\u001b[39;49;00m\u001b[33m branches.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0139:         \u001b[34mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mFound:    [{:03d}] \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(counter) + \u001b[33m'\u001b[39;49;00m\u001b[33m \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(node2) + \\\n",
      "0140:               \u001b[33m'\u001b[39;49;00m\u001b[33m with \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + \u001b[36mstr\u001b[39;49;00m(\u001b[36mlen\u001b[39;49;00m(node2._children)) + \u001b[33m'\u001b[39;49;00m\u001b[33m branches.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0141:         sys.exit()\n",
      "0142: \n",
      "0143:     \u001b[34mdef\u001b[39;49;00m \u001b[32mcompNode\u001b[39;49;00m(node1, node2, counter):\n",
      "0144: \n",
      "0145:         \u001b[34mif\u001b[39;49;00m node1.tag != node2.tag:\n",
      "0146:             printError(node1, node2, counter, \u001b[33m'\u001b[39;49;00m\u001b[33mDifferent tag\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0147: \n",
      "0148:         \u001b[34mif\u001b[39;49;00m node1.text != node2.text:\n",
      "0149:             printError(node1, node2, counter, \u001b[33m'\u001b[39;49;00m\u001b[33mDifferent text\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0150: \n",
      "0151:         keys1 = \u001b[36msorted\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m(node1.attrib.keys()))\n",
      "0152:         keys2 = \u001b[36msorted\u001b[39;49;00m(\u001b[36mlist\u001b[39;49;00m(node2.attrib.keys()))\n",
      "0153: \n",
      "0154:         \u001b[34mif\u001b[39;49;00m keys1 != keys2:\n",
      "0155:             printError(node1, node2, counter, \u001b[33m'\u001b[39;49;00m\u001b[33mDifferent keys\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0156: \n",
      "0157:         \u001b[34mfor\u001b[39;49;00m key \u001b[35min\u001b[39;49;00m keys1:\n",
      "0158:             \u001b[34mif\u001b[39;49;00m node1.get(key) != node2.get(key):\n",
      "0159:                 printError(node1, node2, counter, \u001b[33m'\u001b[39;49;00m\u001b[33mDifferent values\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0160: \n",
      "0161:         \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(node1._children) != \u001b[36mlen\u001b[39;49;00m(node2._children):\n",
      "0162:             printError(node1, node2, counter, \u001b[33m'\u001b[39;49;00m\u001b[33mDifferent number of branches\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0163: \n",
      "0164:         \u001b[34mfor\u001b[39;49;00m i, (n1, n2) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(\u001b[36mzip\u001b[39;49;00m(node1._children, node2._children)):\n",
      "0165:             compNode(n1, n2, counter + i + \u001b[34m1\u001b[39;49;00m)\n",
      "0166: \n",
      "0167:     compNode(tree1, tree2, \u001b[34m0\u001b[39;49;00m)\n",
      "0168:     \u001b[34mreturn\u001b[39;49;00m \u001b[36mTrue\u001b[39;49;00m\n",
      "0169: \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize -O linenos=1 -g dataTree.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**. Cree el siguiente árbol usando `dataTree.py`:\n",
    "\n",
    "```\n",
    "+-- ROOT\n",
    "     +-- A\n",
    "     |   +-- A1\n",
    "     |   +-- A2\n",
    "     |   +-- A3\n",
    "     +-- B\n",
    "     |   +-- B1\n",
    "     |   +-- B2\n",
    "     +-- C\n",
    "         +-- C1\n",
    "         +-- C2\n",
    "         +-- C3 {a: 1, b: 2, c: 3}\n",
    "         +-- C4 {d: 4, e: 5, f: 6}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- ROOT\n",
      "    +-- A\n",
      "    |   +-- A1\n",
      "    |   +-- A2\n",
      "    |   +-- A3\n",
      "    +-- B\n",
      "    |   +-- B1\n",
      "    |   +-- B2\n",
      "    +-- C\n",
      "        +-- C1\n",
      "        +-- C2\n",
      "        +-- C3 {a: 1, b: 2, c: 3}\n",
      "        +-- C4 {d: 4, e: 5, f: 6}\n"
     ]
    }
   ],
   "source": [
    "import dataTree as dt\n",
    "\n",
    "root = dt.TreeNode('ROOT')\n",
    "\n",
    "# todos son hijos del nodo raiz\n",
    "A = dt.SubNode(root, 'A')\n",
    "B = dt.SubNode(root, 'B')\n",
    "C = dt.SubNode(root, 'C')\n",
    "\n",
    "# hijos del nodo A\n",
    "A1 = dt.SubNode(A, 'A1')\n",
    "A2 = dt.SubNode(A, 'A2')\n",
    "A3 = dt.SubNode(A, 'A3')\n",
    "\n",
    "\n",
    "# hijos del nodo B\n",
    "B1 = dt.SubNode(B, 'B1')\n",
    "B2 = dt.SubNode(B, 'B2')\n",
    "\n",
    "# hijos del nodo C\n",
    "C1 = dt.SubNode(C, 'C1')\n",
    "C2 = dt.SubNode(C, 'C2')\n",
    "C3 = dt.SubNode(C, 'C3', dict(a=1, b=2, c=3))\n",
    "C4 = dt.SubNode(C, 'C4', {'d':4, 'e':5, 'f':6})\n",
    "\n",
    "dt.printTree(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**. Salve el arbol al disco y recuperlo en otra variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- ROOT\n",
      "    +-- A\n",
      "    |   +-- A1\n",
      "    |   +-- A2\n",
      "    |   +-- A3\n",
      "    +-- B\n",
      "    |   +-- B1\n",
      "    |   +-- B2\n",
      "    +-- C\n",
      "        +-- C1\n",
      "        +-- C2\n",
      "        +-- C3 {a: 1, b: 2, c: 3}\n",
      "        +-- C4 {d: 4, e: 5, f: 6}\n"
     ]
    }
   ],
   "source": [
    "# lo salva al disco duro\n",
    "import pickle\n",
    "f = open('example.dataTree', 'wb')\n",
    "pickle.dump(root, f)\n",
    "f.close()\n",
    "\n",
    "# lo recupera del disco duro\n",
    "f = open('example.dataTree', 'rb')\n",
    "data = pickle.load(f)\n",
    "f.close()\n",
    "\n",
    "# imprime\n",
    "dt.printTree(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**. Recupere los subarboles desde el arbol `data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- A\n",
      "    +-- A1\n",
      "    +-- A2\n",
      "    +-- A3\n",
      " \n",
      "+-- B\n",
      "    +-- B1\n",
      "    +-- B2\n",
      " \n",
      "+-- C\n",
      "    +-- C1\n",
      "    +-- C2\n",
      "    +-- C3 {a: 1, b: 2, c: 3}\n",
      "    +-- C4 {d: 4, e: 5, f: 6}\n"
     ]
    }
   ],
   "source": [
    "data_A = data.find('A') # la función find permite recuperar el nodo a partir de la propiedad `tag`.\n",
    "data_B = data.find('B')\n",
    "data_C = data.find('C')\n",
    "\n",
    "dt.printTree(data_A)\n",
    "print(' ')\n",
    "dt.printTree(data_B)\n",
    "print(' ')\n",
    "dt.printTree(data_C)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# shlex - Herramienta para construir analizadores léxicos sencillos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import shlex\n",
    "x = '12.4+15.4'\n",
    "s1 = shlex.split(x)\n",
    "s2 = shlex.shlex(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12.4+15.4']\n"
     ]
    }
   ],
   "source": [
    "print(s1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['12', '.', '4', '+', '15', '.', '4']\n"
     ]
    }
   ],
   "source": [
    "print(list(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# yylex.py - Analizador léxico para el lenguaje de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gramática básica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prog \n",
    "  -> fn_decl_list main_prog\n",
    "\n",
    "var_decl \n",
    "  -> ID ‘:’ DATATYPE  [‘,’ ID ‘:’ DATATYPE]*\n",
    "\n",
    "fn_decl_list \n",
    "  -> [ FUNCTION FID ‘:’ DATATYPE ‘(’ [var_decl] ‘)’ \n",
    "       [VAR var_decl ‘;’]\n",
    "       stmt_block ]*\n",
    "\n",
    "stmt_block \n",
    "  -> ‘{’ stmt+ ‘}’\n",
    "   | stmt \n",
    "\n",
    "stmt \n",
    "  -> WRITE [STRING ‘:’] lexpr ‘;’\n",
    "   | INPUT [STRING ‘:’] ID ‘;’\n",
    "   | WHEN  ‘(’ lexpr ‘)’ DO stmt_block\n",
    "   | IF ‘(’ lexpr ‘)’ DO stmt_block ELSE stmt_block \n",
    "   | WHILE ‘(’ expr ‘)’ DO stmt_block\n",
    "   | RETURN  expr ‘;’\n",
    "   | ID ‘:=’ lexp ‘;’\n",
    "\n",
    "lexpr\n",
    "  -> nexpr \n",
    "\n",
    "nexpr \n",
    "  -> rexpr\n",
    "\n",
    "rexpr \n",
    "  -> simple_expr [ (‘<’|‘==’)\n",
    "                   simple_expr ]\n",
    "simple_expr \n",
    "  -> term [ (‘+’) term]*\n",
    "\n",
    "term \n",
    "  -> factor [(‘*’) factor]*\n",
    "\n",
    "factor \n",
    "  -> NUM \n",
    "   | ID \n",
    "   | BOOL\n",
    "   | ‘(’ expr ‘)’  \n",
    "   | FID ‘(’ [lexpr [‘,’ lexpr]*]  ‘)’\n",
    "\n",
    "main_prog \n",
    "  -> [VAR var_decl ‘;’] stmt* END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplos lenguaje bcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "var n:num, i:num, j:num;\n",
    "\n",
    "n := 5;\n",
    "i := 1;\n",
    "\n",
    "while (true) do\n",
    "  {\n",
    "  when (n < i) do break;\n",
    "  j := 1;\n",
    "  while (true) do\n",
    "    {\n",
    "    when (n < j) do break;\n",
    "    write 'i = ': i;\n",
    "    write 'j = ': j;\n",
    "    j++;\n",
    "    }\n",
    "  i++;\n",
    "  }\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- TOKENTABLE\n",
      "    +-- VAR {lexeme: var, lineno: 0}\n",
      "    +-- ID {lexeme: n, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- , {lexeme: ,, lineno: 0}\n",
      "    +-- ID {lexeme: i, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- , {lexeme: ,, lineno: 0}\n",
      "    +-- ID {lexeme: j, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- ; {lexeme: ;, lineno: 0}\n",
      "    +-- ID {lexeme: n, lineno: 2}\n",
      "    +-- := {lexeme: :=, lineno: 2}\n",
      "    +-- NUM {lexeme: 5, lineno: 2}\n",
      "    +-- ; {lexeme: ;, lineno: 2}\n",
      "    +-- ID {lexeme: i, lineno: 3}\n",
      "    +-- := {lexeme: :=, lineno: 3}\n",
      "    +-- NUM {lexeme: 1, lineno: 3}\n",
      "    +-- ; {lexeme: ;, lineno: 3}\n",
      "    +-- WHILE {lexeme: while, lineno: 5}\n",
      "    +-- ( {lexeme: (, lineno: 5}\n",
      "    +-- BOOL {lexeme: true, lineno: 5}\n",
      "    +-- ) {lexeme: ), lineno: 5}\n",
      "    +-- DO {lexeme: do, lineno: 5}\n",
      "    +-- { {lexeme: {, lineno: 6}\n",
      "    +-- WHEN {lexeme: when, lineno: 7}\n",
      "    +-- ( {lexeme: (, lineno: 7}\n",
      "    +-- ID {lexeme: n, lineno: 7}\n",
      "    +-- < {lexeme: <, lineno: 7}\n",
      "    +-- ID {lexeme: i, lineno: 7}\n",
      "    +-- ) {lexeme: ), lineno: 7}\n",
      "    +-- DO {lexeme: do, lineno: 7}\n",
      "    +-- ID {lexeme: break, lineno: 7}\n",
      "    +-- ; {lexeme: ;, lineno: 7}\n",
      "    +-- ID {lexeme: j, lineno: 8}\n",
      "    +-- := {lexeme: :=, lineno: 8}\n",
      "    +-- NUM {lexeme: 1, lineno: 8}\n",
      "    +-- ; {lexeme: ;, lineno: 8}\n",
      "    +-- WHILE {lexeme: while, lineno: 9}\n",
      "    +-- ( {lexeme: (, lineno: 9}\n",
      "    +-- BOOL {lexeme: true, lineno: 9}\n",
      "    +-- ) {lexeme: ), lineno: 9}\n",
      "    +-- DO {lexeme: do, lineno: 9}\n",
      "    +-- { {lexeme: {, lineno: 10}\n",
      "    +-- WHEN {lexeme: when, lineno: 11}\n",
      "    +-- ( {lexeme: (, lineno: 11}\n",
      "    +-- ID {lexeme: n, lineno: 11}\n",
      "    +-- < {lexeme: <, lineno: 11}\n",
      "    +-- ID {lexeme: j, lineno: 11}\n",
      "    +-- ) {lexeme: ), lineno: 11}\n",
      "    +-- DO {lexeme: do, lineno: 11}\n",
      "    +-- ID {lexeme: break, lineno: 11}\n",
      "    +-- ; {lexeme: ;, lineno: 11}\n",
      "    +-- WRITE {lexeme: write, lineno: 12}\n",
      "    +-- STR {lexeme: 'i = ', lineno: 12}\n",
      "    +-- : {lexeme: :, lineno: 12}\n",
      "    +-- ID {lexeme: i, lineno: 12}\n",
      "    +-- ; {lexeme: ;, lineno: 12}\n",
      "    +-- WRITE {lexeme: write, lineno: 13}\n",
      "    +-- STR {lexeme: 'j = ', lineno: 13}\n",
      "    +-- : {lexeme: :, lineno: 13}\n",
      "    +-- ID {lexeme: j, lineno: 13}\n",
      "    +-- ; {lexeme: ;, lineno: 13}\n",
      "    +-- ID {lexeme: j, lineno: 14}\n",
      "    +-- + {lexeme: +, lineno: 14}\n",
      "    +-- + {lexeme: +, lineno: 14}\n",
      "    +-- ; {lexeme: ;, lineno: 14}\n",
      "    +-- } {lexeme: }, lineno: 15}\n",
      "    +-- ID {lexeme: i, lineno: 16}\n",
      "    +-- + {lexeme: +, lineno: 16}\n",
      "    +-- + {lexeme: +, lineno: 16}\n",
      "    +-- ; {lexeme: ;, lineno: 16}\n",
      "    +-- } {lexeme: }, lineno: 17}\n",
      "    +-- END {lexeme: end, lineno: 19}\n",
      "    +-- END {lexeme: end, lineno: 1}\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "python yylex.py example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "var z:num;\n",
    "z := 0;    \n",
    "do \n",
    "  {\n",
    "  z := z + 1;\n",
    "  write 'do while (1 a 10) ==> ':  z;\n",
    "  } \n",
    "  while (z < 10)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- TOKENTABLE\n",
      "    +-- VAR {lexeme: var, lineno: 0}\n",
      "    +-- ID {lexeme: z, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- ; {lexeme: ;, lineno: 0}\n",
      "    +-- ID {lexeme: z, lineno: 1}\n",
      "    +-- := {lexeme: :=, lineno: 1}\n",
      "    +-- NUM {lexeme: 0, lineno: 1}\n",
      "    +-- ; {lexeme: ;, lineno: 1}\n",
      "    +-- DO {lexeme: do, lineno: 2}\n",
      "    +-- { {lexeme: {, lineno: 3}\n",
      "    +-- ID {lexeme: z, lineno: 4}\n",
      "    +-- := {lexeme: :=, lineno: 4}\n",
      "    +-- ID {lexeme: z, lineno: 4}\n",
      "    +-- + {lexeme: +, lineno: 4}\n",
      "    +-- NUM {lexeme: 1, lineno: 4}\n",
      "    +-- ; {lexeme: ;, lineno: 4}\n",
      "    +-- WRITE {lexeme: write, lineno: 5}\n",
      "    +-- STR {lexeme: 'do while (1 a 10) ==> ', lineno: 5}\n",
      "    +-- : {lexeme: :, lineno: 5}\n",
      "    +-- ID {lexeme: z, lineno: 5}\n",
      "    +-- ; {lexeme: ;, lineno: 5}\n",
      "    +-- } {lexeme: }, lineno: 6}\n",
      "    +-- WHILE {lexeme: while, lineno: 7}\n",
      "    +-- ( {lexeme: (, lineno: 7}\n",
      "    +-- ID {lexeme: z, lineno: 7}\n",
      "    +-- < {lexeme: <, lineno: 7}\n",
      "    +-- NUM {lexeme: 10, lineno: 7}\n",
      "    +-- ) {lexeme: ), lineno: 7}\n",
      "    +-- END {lexeme: end, lineno: 9}\n",
      "    +-- END {lexeme: end, lineno: 1}\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "python yylex.py example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "write '$chs( 1 ) ==> ':  \\$chs( 1 );\n",
    "write '$abs( 1 ) ==> ':  \\$abs( 1 );\n",
    "write '$sgn( 0 ) ==> ':  \\$sgn( 0 );\n",
    "write '$sgn( 1 ) ==> ':  \\$sgn( 1 );\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example.txt:Lexical error at line <0>: Unexpected symbol <\\>\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "python yylex.py example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting example.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile example.txt\n",
    "function @min:num (x:num, y:num)\n",
    "   {\n",
    "   when ((x < y) == true) do return x;\n",
    "   return y;\n",
    "   }\n",
    "   \n",
    "## funcion max(x, y)\n",
    "function @max:num (x:num, y:num)   \n",
    "   {\n",
    "   if ((x < y) == false) do\n",
    "      {\n",
    "      return x;\n",
    "      }\n",
    "   else\n",
    "      {                 \n",
    "      return y;\n",
    "      }\n",
    "   }\n",
    "\n",
    "write 'min 1 -> ': @min(1,2);\n",
    "write 'max 2 -> ': @max(1,2);\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-- TOKENTABLE\n",
      "    +-- FUNCTION {lexeme: function, lineno: 0}\n",
      "    +-- UFID {lexeme: @min, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- ( {lexeme: (, lineno: 0}\n",
      "    +-- ID {lexeme: x, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- , {lexeme: ,, lineno: 0}\n",
      "    +-- ID {lexeme: y, lineno: 0}\n",
      "    +-- : {lexeme: :, lineno: 0}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 0}\n",
      "    +-- ) {lexeme: ), lineno: 0}\n",
      "    +-- { {lexeme: {, lineno: 1}\n",
      "    +-- WHEN {lexeme: when, lineno: 2}\n",
      "    +-- ( {lexeme: (, lineno: 2}\n",
      "    +-- ( {lexeme: (, lineno: 2}\n",
      "    +-- ID {lexeme: x, lineno: 2}\n",
      "    +-- < {lexeme: <, lineno: 2}\n",
      "    +-- ID {lexeme: y, lineno: 2}\n",
      "    +-- ) {lexeme: ), lineno: 2}\n",
      "    +-- == {lexeme: ==, lineno: 2}\n",
      "    +-- BOOL {lexeme: true, lineno: 2}\n",
      "    +-- ) {lexeme: ), lineno: 2}\n",
      "    +-- DO {lexeme: do, lineno: 2}\n",
      "    +-- RETURN {lexeme: return, lineno: 2}\n",
      "    +-- ID {lexeme: x, lineno: 2}\n",
      "    +-- ; {lexeme: ;, lineno: 2}\n",
      "    +-- RETURN {lexeme: return, lineno: 3}\n",
      "    +-- ID {lexeme: y, lineno: 3}\n",
      "    +-- ; {lexeme: ;, lineno: 3}\n",
      "    +-- } {lexeme: }, lineno: 4}\n",
      "    +-- FUNCTION {lexeme: function, lineno: 7}\n",
      "    +-- UFID {lexeme: @max, lineno: 7}\n",
      "    +-- : {lexeme: :, lineno: 7}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 7}\n",
      "    +-- ( {lexeme: (, lineno: 7}\n",
      "    +-- ID {lexeme: x, lineno: 7}\n",
      "    +-- : {lexeme: :, lineno: 7}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 7}\n",
      "    +-- , {lexeme: ,, lineno: 7}\n",
      "    +-- ID {lexeme: y, lineno: 7}\n",
      "    +-- : {lexeme: :, lineno: 7}\n",
      "    +-- DATATYPE {lexeme: num, lineno: 7}\n",
      "    +-- ) {lexeme: ), lineno: 7}\n",
      "    +-- { {lexeme: {, lineno: 8}\n",
      "    +-- IF {lexeme: if, lineno: 9}\n",
      "    +-- ( {lexeme: (, lineno: 9}\n",
      "    +-- ( {lexeme: (, lineno: 9}\n",
      "    +-- ID {lexeme: x, lineno: 9}\n",
      "    +-- < {lexeme: <, lineno: 9}\n",
      "    +-- ID {lexeme: y, lineno: 9}\n",
      "    +-- ) {lexeme: ), lineno: 9}\n",
      "    +-- == {lexeme: ==, lineno: 9}\n",
      "    +-- BOOL {lexeme: false, lineno: 9}\n",
      "    +-- ) {lexeme: ), lineno: 9}\n",
      "    +-- DO {lexeme: do, lineno: 9}\n",
      "    +-- { {lexeme: {, lineno: 10}\n",
      "    +-- RETURN {lexeme: return, lineno: 11}\n",
      "    +-- ID {lexeme: x, lineno: 11}\n",
      "    +-- ; {lexeme: ;, lineno: 11}\n",
      "    +-- } {lexeme: }, lineno: 12}\n",
      "    +-- ELSE {lexeme: else, lineno: 13}\n",
      "    +-- { {lexeme: {, lineno: 14}\n",
      "    +-- RETURN {lexeme: return, lineno: 15}\n",
      "    +-- ID {lexeme: y, lineno: 15}\n",
      "    +-- ; {lexeme: ;, lineno: 15}\n",
      "    +-- } {lexeme: }, lineno: 16}\n",
      "    +-- } {lexeme: }, lineno: 17}\n",
      "    +-- WRITE {lexeme: write, lineno: 19}\n",
      "    +-- STR {lexeme: 'min 1 -> ', lineno: 19}\n",
      "    +-- : {lexeme: :, lineno: 19}\n",
      "    +-- UFID {lexeme: @min, lineno: 19}\n",
      "    +-- ( {lexeme: (, lineno: 19}\n",
      "    +-- NUM {lexeme: 1, lineno: 19}\n",
      "    +-- , {lexeme: ,, lineno: 19}\n",
      "    +-- NUM {lexeme: 2, lineno: 19}\n",
      "    +-- ) {lexeme: ), lineno: 19}\n",
      "    +-- ; {lexeme: ;, lineno: 19}\n",
      "    +-- WRITE {lexeme: write, lineno: 20}\n",
      "    +-- STR {lexeme: 'max 2 -> ', lineno: 20}\n",
      "    +-- : {lexeme: :, lineno: 20}\n",
      "    +-- UFID {lexeme: @max, lineno: 20}\n",
      "    +-- ( {lexeme: (, lineno: 20}\n",
      "    +-- NUM {lexeme: 1, lineno: 20}\n",
      "    +-- , {lexeme: ,, lineno: 20}\n",
      "    +-- NUM {lexeme: 2, lineno: 20}\n",
      "    +-- ) {lexeme: ), lineno: 20}\n",
      "    +-- ; {lexeme: ;, lineno: 20}\n",
      "    +-- END {lexeme: end, lineno: 22}\n",
      "    +-- END {lexeme: end, lineno: 1}\n"
     ]
    }
   ],
   "source": [
    "%%sh \n",
    "python yylex.py example.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Implementación de yylex.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001: \u001b[37m###< 2016-08-28 17:04:40.182335 >###\u001b[39;49;00m\n",
      "0002: \n",
      "0003: \u001b[37m#\u001b[39;49;00m\n",
      "0004: \u001b[37m#  yylex.py\u001b[39;49;00m\n",
      "0005: \u001b[37m#    analizador lexico para el lenguaje bcc\u001b[39;49;00m\n",
      "0006: \u001b[37m#\u001b[39;49;00m\n",
      "0007: \n",
      "0008: \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m, \u001b[04m\u001b[36mshlex\u001b[39;49;00m, \u001b[04m\u001b[36mpickle\u001b[39;49;00m\n",
      "0009: \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mdataTree\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mdt\u001b[39;49;00m\n",
      "0010: \n",
      "0011: \u001b[37m#\u001b[39;49;00m\n",
      "0012: \u001b[37m# analizador lexico\u001b[39;49;00m\n",
      "0013: \u001b[37m#\u001b[39;49;00m\n",
      "0014: \u001b[34mdef\u001b[39;49;00m \u001b[32myylex\u001b[39;49;00m(filename, quiet=\u001b[36mFalse\u001b[39;49;00m):\n",
      "0015: \n",
      "0016:     \u001b[37m# estructura de datos.\u001b[39;49;00m\n",
      "0017:     \u001b[37m#   crea un arbol para almacenar la informacion\u001b[39;49;00m\n",
      "0018:     \u001b[37m#   generada por las distintas componentes\u001b[39;49;00m\n",
      "0019:     \u001b[37m#   del interprete\u001b[39;49;00m\n",
      "0020:     DATA = dt.TreeNode(\u001b[33m'\u001b[39;49;00m\u001b[33mDATA\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, {\u001b[33m'\u001b[39;49;00m\u001b[33mfilename\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: filename})\n",
      "0021:     SOURCECODE  = dt.SubNode(DATA, \u001b[33m'\u001b[39;49;00m\u001b[33mSOURCECODE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0022:     TOKENTABLE  = dt.SubNode(DATA, \u001b[33m'\u001b[39;49;00m\u001b[33mTOKENTABLE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0023:     SYNTAXTREE  = dt.SubNode(DATA, \u001b[33m'\u001b[39;49;00m\u001b[33mSYNTAXTREE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0024:     SYMBOLTABLE = dt.SubNode(DATA, \u001b[33m'\u001b[39;49;00m\u001b[33mSYMBOLTABLE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "0025: \n",
      "0026:     \u001b[37m# preparacion del codigo fuente.\u001b[39;49;00m\n",
      "0027:     \u001b[37m#   sourceCode es un vector donde cada elemento\u001b[39;49;00m\n",
      "0028:     \u001b[37m#   es una linea del codigo fuente incluyendo\u001b[39;49;00m\n",
      "0029:     \u001b[37m#   comentarios. Despues almacena el codigo\u001b[39;49;00m\n",
      "0030:     \u001b[37m#   en la estructura de datos\u001b[39;49;00m\n",
      "0031:     sourceCode = \u001b[36mopen\u001b[39;49;00m(filename, \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).readlines()\n",
      "0032:     \u001b[34mfor\u001b[39;49;00m i, line \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(sourceCode):\n",
      "0033:         lineno = i\n",
      "0034:         x = dt.SubNode(SOURCECODE, lineno)\n",
      "0035:         \u001b[34mif\u001b[39;49;00m line[-\u001b[34m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0036:             line = line[:-\u001b[34m1\u001b[39;49;00m]\n",
      "0037:         x.text = line\n",
      "0038: \n",
      "0039:     \u001b[37m#\u001b[39;49;00m\n",
      "0040:     \u001b[37m# yyputtoken.\u001b[39;49;00m\n",
      "0041:     \u001b[37m#   esta es uan funcion auxiliar que agrega cada token y su\u001b[39;49;00m\n",
      "0042:     \u001b[37m#   correspondiente lexema a la tabla de tokens de forma\u001b[39;49;00m\n",
      "0043:     \u001b[37m#   secuencial.\u001b[39;49;00m\n",
      "0044:     \u001b[37m#   yyputtoken crea un nuevo nodo a la tabla se simbolos\u001b[39;49;00m\n",
      "0045:     \u001b[37m#\u001b[39;49;00m\n",
      "0046:     \u001b[34mdef\u001b[39;49;00m \u001b[32myyputtoken\u001b[39;49;00m(token, lexeme, lineno):\n",
      "0047:         \u001b[37m#\u001b[39;49;00m\n",
      "0048:         dt.SubNode(TOKENTABLE, token, \u001b[36mdict\u001b[39;49;00m(lexeme=lexeme, lineno=lineno))\n",
      "0049:         \u001b[37m#\u001b[39;49;00m\n",
      "0050: \n",
      "0051: \n",
      "0052:     \u001b[37m# analizador lexico.\u001b[39;49;00m\n",
      "0053:     \u001b[37m#   esta es la rutina de analisis lexico como tal.\u001b[39;49;00m\n",
      "0054:     \u001b[37m#   se procesa una linea a la vez, para todas las\u001b[39;49;00m\n",
      "0055:     \u001b[37m#   lineas del codigo fuente\u001b[39;49;00m\n",
      "0056:     lineno = -\u001b[34m1\u001b[39;49;00m\n",
      "0057:     \u001b[34mfor\u001b[39;49;00m line \u001b[35min\u001b[39;49;00m sourceCode:\n",
      "0058: \n",
      "0059:         \u001b[37m# shlex.\u001b[39;49;00m\n",
      "0060:         \u001b[37m#   es una utilidad de python que permite descomponer\u001b[39;49;00m\n",
      "0061:         \u001b[37m#   una cadena de texto en sus lexemas componentes. shlex\u001b[39;49;00m\n",
      "0062:         \u001b[37m#   descarta automaticamente las lineas de comentarios.\u001b[39;49;00m\n",
      "0063:         \u001b[37m#\u001b[39;49;00m\n",
      "0064:         \u001b[37m# lexemes.\u001b[39;49;00m\n",
      "0065:         \u001b[37m#   es una lista de strings, donde cada string es un lexema\u001b[39;49;00m\n",
      "0066:         lexemes = \u001b[36mlist\u001b[39;49;00m(shlex.shlex(line))\n",
      "0067: \n",
      "0068:         n = \u001b[34m0\u001b[39;49;00m\n",
      "0069:         lineno += \u001b[34m1\u001b[39;49;00m\n",
      "0070:         \u001b[34mwhile\u001b[39;49;00m n < \u001b[36mlen\u001b[39;49;00m(lexemes):\n",
      "0071:             \u001b[37m# lex1:  es el lexema actual\u001b[39;49;00m\n",
      "0072:             \u001b[37m# lex2:  es el lexema actual concatenado con el\u001b[39;49;00m\n",
      "0073:             \u001b[37m#        siguiente. se requiere para poder reconocer\u001b[39;49;00m\n",
      "0074:             \u001b[37m#        algunas secuencias como '>=' que shlex\u001b[39;49;00m\n",
      "0075:             \u001b[37m#        separa en '>' y '='\u001b[39;49;00m\n",
      "0076:             lex1 = lexemes[n]\n",
      "0077:             lex2 = lexemes[n] + lexemes[n+\u001b[34m1\u001b[39;49;00m] \u001b[34mif\u001b[39;49;00m n+\u001b[34m1\u001b[39;49;00m < \u001b[36mlen\u001b[39;49;00m(lexemes) \u001b[34melse\u001b[39;49;00m \u001b[36mNone\u001b[39;49;00m\n",
      "0078: \n",
      "0079:             \u001b[37m#  en este punto se inicia el reconocimiento de cada\u001b[39;49;00m\n",
      "0080:             \u001b[37m#  uno de los lexemas que conforman el codigo fuente\u001b[39;49;00m\n",
      "0081:             \u001b[34mif\u001b[39;49;00m lex1[\u001b[34m0\u001b[39;49;00m] == \u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[35mor\u001b[39;49;00m lex1[\u001b[34m0\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0082:                 \u001b[37m#\u001b[39;49;00m\n",
      "0083:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mSTR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0084:                 \u001b[37m#\u001b[39;49;00m\n",
      "0085:             \u001b[34melif\u001b[39;49;00m lex1 \u001b[35min\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mfunction var end write when do if else while return\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.split():\n",
      "0086:                 \u001b[37m#\u001b[39;49;00m\n",
      "0087:                 yyputtoken(lex1.upper(), lex1, lineno)\n",
      "0088:                 \u001b[37m#\u001b[39;49;00m\n",
      "0089: \n",
      "0090: \n",
      "0091:             \u001b[34melif\u001b[39;49;00m lex2 \u001b[35min\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m:= ==\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.split():\n",
      "0092:                 yyputtoken(lex2, lex2, lineno)\n",
      "0093:                 n += \u001b[34m1\u001b[39;49;00m\n",
      "0094: \n",
      "0095: \n",
      "0096:             \u001b[34melif\u001b[39;49;00m lex1 \u001b[35min\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33m: , ; ( ) { } < + *\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.split():\n",
      "0097:                 yyputtoken(lex1, lex1, lineno)\n",
      "0098: \n",
      "0099: \n",
      "0100:             \u001b[34melif\u001b[39;49;00m lex1 \u001b[35min\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mtrue false\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.split():\n",
      "0101:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mBOOL\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0102: \n",
      "0103:             \u001b[34melif\u001b[39;49;00m lex1 \u001b[35min\u001b[39;49;00m \u001b[33m'\u001b[39;49;00m\u001b[33mbool num\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.split():\n",
      "0104:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mDATATYPE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0105: \n",
      "0106:             \u001b[34melif\u001b[39;49;00m lex1 == \u001b[33m'\u001b[39;49;00m\u001b[33m@\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0107:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mUFID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex2, lineno)\n",
      "0108:                 n += \u001b[34m1\u001b[39;49;00m\n",
      "0109: \n",
      "0110:             \u001b[34melif\u001b[39;49;00m lex1 == \u001b[33m'\u001b[39;49;00m\u001b[33m$\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0111:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mBFID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex2, lineno)\n",
      "0112:                 n += \u001b[34m1\u001b[39;49;00m\n",
      "0113: \n",
      "0114:             \u001b[34melif\u001b[39;49;00m (lex1 == \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m \u001b[35mand\u001b[39;49;00m\n",
      "0115:                   n+\u001b[34m1\u001b[39;49;00m < \u001b[36mlen\u001b[39;49;00m(lexemes) \u001b[35mand\u001b[39;49;00m\n",
      "0116:                   lexemes[n+\u001b[34m1\u001b[39;49;00m].isdigit()):\n",
      "0117:                 lex1 = \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m + lexemes[n+\u001b[34m1\u001b[39;49;00m]\n",
      "0118:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mNUM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0119:                 n += \u001b[34m1\u001b[39;49;00m\n",
      "0120: \n",
      "0121:             \u001b[34melif\u001b[39;49;00m lex1.isdigit():\n",
      "0122:                 \u001b[34mif\u001b[39;49;00m n+\u001b[34m1\u001b[39;49;00m < \u001b[36mlen\u001b[39;49;00m(lexemes) \u001b[35mand\u001b[39;49;00m lexemes[n+\u001b[34m1\u001b[39;49;00m] == \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0123:                     lex1 += \u001b[33m'\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\n",
      "0124:                     n += \u001b[34m1\u001b[39;49;00m\n",
      "0125:                     \u001b[34mif\u001b[39;49;00m n+\u001b[34m1\u001b[39;49;00m < \u001b[36mlen\u001b[39;49;00m(lexemes) \u001b[35mand\u001b[39;49;00m lexemes[n+\u001b[34m1\u001b[39;49;00m].isdigit():\n",
      "0126:                         lex1 += lexemes[n+\u001b[34m1\u001b[39;49;00m]\n",
      "0127:                         n += \u001b[34m1\u001b[39;49;00m\n",
      "0128:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mNUM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0129: \n",
      "0130:             \u001b[34melif\u001b[39;49;00m lex1.isalnum():\n",
      "0131:                 yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mID\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, lex1, lineno)\n",
      "0132: \n",
      "0133:             \u001b[34melse\u001b[39;49;00m:\n",
      "0134:                 msg = \u001b[33m'\u001b[39;49;00m\u001b[33m{}:Lexical error at line <{}>: \u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(filename, lineno)\n",
      "0135:                 msg += \u001b[33m'\u001b[39;49;00m\u001b[33mUnexpected symbol <{}>\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(lex1)\n",
      "0136:                 \u001b[37m# msg += '--> ' + sourceCode[lineno]\u001b[39;49;00m\n",
      "0137:                 \u001b[34mprint\u001b[39;49;00m(msg)\n",
      "0138:                 sys.exit()\n",
      "0139: \n",
      "0140:             n += \u001b[34m1\u001b[39;49;00m\n",
      "0141: \n",
      "0142:     yyputtoken(\u001b[33m'\u001b[39;49;00m\u001b[33mEND\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mlen\u001b[39;49;00m(lexemes))\n",
      "0143: \n",
      "0144:     \u001b[37m# en este punto se han reconocido todos los\u001b[39;49;00m\n",
      "0145:     \u001b[37m# lexemas y se procede a almacenar el resultado\u001b[39;49;00m\n",
      "0146:     \u001b[37m# en un archivo en disco\u001b[39;49;00m\n",
      "0147:     \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(filename + \u001b[33m'\u001b[39;49;00m\u001b[33m.dataTree\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "0148:         pickle.dump(DATA, f)\n",
      "0149: \n",
      "0150:     \u001b[34mif\u001b[39;49;00m quiet == \u001b[36mFalse\u001b[39;49;00m:\n",
      "0151:         \u001b[37m#\u001b[39;49;00m\n",
      "0152:         dt.printTree(TOKENTABLE)\n",
      "0153:         \u001b[37m#\u001b[39;49;00m\n",
      "0154: \n",
      "0155: \n",
      "0156: \u001b[34mif\u001b[39;49;00m __name__ == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "0157: \n",
      "0158: \n",
      "0159:     \u001b[34mif\u001b[39;49;00m \u001b[36mlen\u001b[39;49;00m(sys.argv) > \u001b[34m1\u001b[39;49;00m:\n",
      "0160:         \u001b[34mfor\u001b[39;49;00m filename \u001b[35min\u001b[39;49;00m sys.argv[\u001b[34m1\u001b[39;49;00m:]:\n",
      "0161:             yylex(filename)\n",
      "0162:     \u001b[34melse\u001b[39;49;00m:\n",
      "0163:         filename = \u001b[36minput\u001b[39;49;00m()\n",
      "0164:         yylex(filename)\n",
      "0165: \n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "pygmentize -O linenos=1 -g yylex.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gramática extendida para el lenguaje final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "prog \n",
    "  -> fn_decl_list main_prog\n",
    "\n",
    "var_decl \n",
    "  -> ID ‘:’ DATATYPE  [‘,’ ID ‘:’ DATATYPE]*\n",
    "\n",
    "fn_decl_list \n",
    "  -> [ FUNCTION FID ‘:’ DATATYPE ‘(’ [var_decl] ‘)’ \n",
    "       [VAR var_decl ‘;’]\n",
    "       stmt_block ]*\n",
    "\n",
    "stmt_block \n",
    "  -> ‘{’ stmt+ ‘}’\n",
    "   | stmt \n",
    "\n",
    "stmt \n",
    "  -> WRITE [STRING ‘:’] lexpr ‘;’\n",
    "   | INPUT [STRING ‘:’] ID ‘;’\n",
    "   | WHEN  ‘(’ lexpr ‘)’ DO stmt_block\n",
    "   | IF ‘(’ lexpr ‘)’ DO stmt_block ELSE stmt_block \n",
    "   | UNLESS ‘(’ lexpr ‘)’ DO stmt_block \n",
    "   | WHILE ‘(’ expr ‘)’ DO stmt_block\n",
    "   | RETURN  expr ‘;’\n",
    "   | UNTIL ‘(’ lexpr ‘)’ DO stmt_block\n",
    "   | LOOP stmt_block\n",
    "   | DO stmt_block WHILE ‘(’ lexpr ‘)’\n",
    "   | DO stmt_block UNTIL ‘(’ lexpr ‘)’\n",
    "   | REPEAT NUM ‘:’ stmt_block\n",
    "   | FOR ID ‘:=’ lexpr TO lexpr DO stmt_block\n",
    "   | END ‘;’\n",
    "   | NEXT ‘;’\n",
    "   | BREAK ‘;’\n",
    "   | ID ‘:=’ lexp ‘;’\n",
    "   | ID ‘+=’ lexpr ‘;’\n",
    "   | ID ‘-=’ lexpr ‘;’\n",
    "   | ID ‘*=’ lexpr ‘;’\n",
    "   | ID ‘/=’ lexpr ‘;’\n",
    "   | ID ‘%=’ lexpr ‘;’\n",
    "   | ID ‘++’ ‘;’\n",
    "   | ID ‘--’ ‘;’\n",
    "\n",
    "lexpr\n",
    "  -> nexpr [[AND nexpr]* | [OR nexpr]*]\n",
    "\n",
    "nexpr \n",
    "  -> NOT ‘(‘ lexpr  ‘)’  \n",
    "   | rexpr\n",
    "\n",
    "rexpr \n",
    "  -> simple_expr [ (‘<’|‘==’|‘<=’|‘>’|‘>=’|‘!=’)\n",
    "                   simple_expr ]\n",
    "simple_expr \n",
    "  -> term [ (‘+’|‘-’) term]*\n",
    "\n",
    "term \n",
    "  -> factor [(‘*’|‘/’) factor]*\n",
    "\n",
    "factor \n",
    "  -> NUM \n",
    "   | ID \n",
    "   | BOOL\n",
    "   | ‘(’ expr ‘)’  \n",
    "   | FID ‘(’ [lexpr [‘,’ lexpr]*]  ‘)’\n",
    "\n",
    "main_prog \n",
    "  -> [VAR var_decl ‘;’] stmt* END\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Contenido](#Contenido)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
